# **Analyzing Developer Conversations with ChatGPT**  

## **Overview**  
This project explores **developer interactions with ChatGPT**, leveraging **natural language processing (NLP) and machine learning** techniques to analyze prompt structures, issue resolution patterns, and the predictability of conversation length. Using **GitHub discussions and issue reports** as a dataset, we aim to uncover **key insights into how developers seek AI assistance** and determine whether specific prompt characteristics influence conversation outcomes.  

## **Research Questions**  
1. **What types of issues do developers bring to ChatGPT?**  
2. **Do structured prompts correlate with successful issue resolution?**  
3. **Can we accurately predict the length of a conversation based on the initial prompt and context?**  

## **Project Structure**  

```plaintext
d542_group6/
â”‚â”€â”€ data/                # Raw dataset (GitHub issues & discussions)
â”‚â”€â”€ data_cleaning/       # Preprocessing scripts & cleaned datasets
â”‚â”€â”€ RQ1/                 # Analysis & results for Research Question 1
â”‚â”€â”€ RQ2/                 # Analysis & results for Research Question 2
â”‚â”€â”€ RQ7/                 # Analysis & results for Research Question 7
â”‚â”€â”€ Project.pdf          # Final project report
â”‚â”€â”€ .gitattributes       # Git tracking settings
â”‚â”€â”€ .DS_Store            # macOS system file (ignore)
```

## **Methodology**  
### **1. Data Processing**  
- **Data Cleaning:** Extracted and normalized data from GitHub discussions and issues (August 31, 2023 snapshot).  
- **Language Filtering:** Kept only English conversations for better NLP performance.  
- **Feature Engineering:** Extracted **textual features (word counts, sentiment, lexical diversity), code presence (via regex), and topic modeling (LDA, TF-IDF, embeddings)**.  

### **2. NLP Analysis & Machine Learning**  
- **Topic Modeling:** Identified common themes in developer queries using **Latent Dirichlet Allocation (LDA)**.  
- **Prompt Structuring & Issue Resolution:** Analyzed correlation between **prompt clarity and successful resolution** using **clustering techniques (K-means, WH-word analysis)**.  
- **Conversation Length Prediction:** Trained **random forest, gradient boosting, and neural networks** to predict conversation length.  

### **3. Model Evaluation**  
- **Random Forest achieved the best results**, though the overall prediction accuracy remained limited (**RÂ² â‰ˆ 0.35, MAE â‰ˆ 9.68 prompts**).  
- **Findings indicate that structured, well-defined prompts lead to shorter, more effective conversations**, while vague prompts often result in longer, unresolved discussions.  

## **Key Findings**  
âœ” Developers primarily use ChatGPT for **debugging, implementation guidance, and theoretical questions**.  
âœ” **Clear, structured prompts are linked to higher issue resolution rates**, whereas ambiguous queries often lead to unresolved cases.  
âœ” **Predicting conversation length is challenging**, as many external factors influence user interactions beyond textual features.  

## **Future Work**  
ðŸ”¹ Explore **advanced deep learning models (transformers, GPT embeddings)** to improve prediction accuracy.  
ðŸ”¹ Integrate **richer metadata (developer expertise, response sentiment, engagement metrics)** for deeper insights.  
ðŸ”¹ Analyze **sequential conversation flow** to understand how discussions evolve over time.  

## **How to Run This Project**  
1. Clone the repository:  
   ```bash
   git clone https://github.com/your-repo/d542_group6.git
   cd d542_group6
   ```  
2. Install dependencies:  
   ```bash
   pip install -r requirements.txt
   ```  
3. Run individual analysis scripts within the `RQ1`, `RQ2`, and `RQ7` folders.  
4. For full conversation length prediction, navigate to `RQ7` and execute the modeling script.  

## **References**  
- **NAIST (2023).** DevGPT Dataset.  
- **Chollet, F. (2023).** *Keras Sequential Model Guide.* Retrieved from [https://keras.io/guides/sequential_model/](https://keras.io/guides/sequential_model/)  
- **OpenAI & DeepSeek (2024).** Model architecture suggestions for neural network implementation.  
