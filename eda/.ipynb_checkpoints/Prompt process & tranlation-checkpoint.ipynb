{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import ast\n",
    "\n",
    "data_gpt = pd.read_json('/Users/zhengqijia/Downloads/ubc/542/DevGPT/snapshot_20230831/20230831_061759_issue_sharings.json')\n",
    "print('data_gpt')\n",
    "display(data_gpt.head())\n",
    "\n",
    "# give some structure to the data\n",
    "data_gpt2 = json_normalize(data_gpt['Sources'])\n",
    "\n",
    "print('data_gpt2')\n",
    "display(data_gpt2.head())\n",
    "print(len(data_gpt2))\n",
    "\n",
    "# Normalizar los datos de la columna ChatgptSharing\n",
    "chatgpt_data = json_normalize(data_gpt2['ChatgptSharing'].explode())\n",
    "\n",
    "# Mostrar los primeros resultados\n",
    "print('chatgpt_data')\n",
    "display(chatgpt_data.head())\n",
    "\n",
    "print(len(chatgpt_data))\n",
    "\n",
    "# Normalizar los datos de la columna ChatgptSharing\n",
    "conversation_data = json_normalize(chatgpt_data['Conversations'].explode())\n",
    "\n",
    "# Mostrar los primeros resultados\n",
    "print('conversation')\n",
    "display(conversation_data.head())\n",
    "\n",
    "print(len(conversation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_prompt(prompt):\n",
    "    if isinstance(prompt, str):\n",
    "        index = prompt.lower().find('html')\n",
    "        return prompt[:index] if index != -1 else prompt\n",
    "    else:\n",
    "        return prompt\n",
    "\n",
    "conversation_data['Processed_Prompt'] = conversation_data['Prompt'].apply(process_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec030cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "def translate_non_english(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text \n",
    "\n",
    "    translator = GoogleTranslator()\n",
    "    translated_parts = []\n",
    "    parts = re.split(r'([^\\x00-\\x7F]+)', text)  \n",
    "    \n",
    "    for part in parts:\n",
    "        if part.strip() and not part.isascii():\n",
    "            try:\n",
    "                translated = translator.translate(part, target='en')\n",
    "                translated_parts.append(translated if translated else \"\")\n",
    "            except Exception as e:\n",
    "                print(f\"Translation error: {e}\")\n",
    "                translated_parts.append(part) \n",
    "        else:\n",
    "            translated_parts.append(part)\n",
    "\n",
    "    return ''.join(translated_parts)\n",
    "\n",
    "conversation_data['Translated_Prompt'] = conversation_data['Processed_Prompt'].apply(translate_non_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3736d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "word_freq = Counter()\n",
    "\n",
    "for i in range(len(conversation_data['Translated_Prompt'])):\n",
    "    print(i)\n",
    "    text = conversation_data['Translated_Prompt'][i]\n",
    "    if isinstance(text, str):\n",
    "        doc = nlp(text)\n",
    "        word_freq.update([token.text.lower() for token in doc if not token.is_punct])\n",
    "\n",
    "print(word_freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
